.\" Automatically generated by Pod::Man 2.16 (Pod::Simple 3.05)
.\"
.\" Standard preamble:
.\" ========================================================================
.de Sh \" Subsection heading
.br
.if t .Sp
.ne 5
.PP
\fB\\$1\fR
.PP
..
.de Sp \" Vertical space (when we can't use .PP)
.if t .sp .5v
.if n .sp
..
.de Vb \" Begin verbatim text
.ft CW
.nf
.ne \\$1
..
.de Ve \" End verbatim text
.ft R
.fi
..
.\" Set up some character translations and predefined strings.  \*(-- will
.\" give an unbreakable dash, \*(PI will give pi, \*(L" will give a left
.\" double quote, and \*(R" will give a right double quote.  \*(C+ will
.\" give a nicer C++.  Capital omega is used to do unbreakable dashes and
.\" therefore won't be available.  \*(C` and \*(C' expand to `' in nroff,
.\" nothing in troff, for use with C<>.
.tr \(*W-
.ds C+ C\v'-.1v'\h'-1p'\s-2+\h'-1p'+\s0\v'.1v'\h'-1p'
.ie n \{\
.    ds -- \(*W-
.    ds PI pi
.    if (\n(.H=4u)&(1m=24u) .ds -- \(*W\h'-12u'\(*W\h'-12u'-\" diablo 10 pitch
.    if (\n(.H=4u)&(1m=20u) .ds -- \(*W\h'-12u'\(*W\h'-8u'-\"  diablo 12 pitch
.    ds L" ""
.    ds R" ""
.    ds C` ""
.    ds C' ""
'br\}
.el\{\
.    ds -- \|\(em\|
.    ds PI \(*p
.    ds L" ``
.    ds R" ''
'br\}
.\"
.\" Escape single quotes in literal strings from groff's Unicode transform.
.ie \n(.g .ds Aq \(aq
.el       .ds Aq '
.\"
.\" If the F register is turned on, we'll generate index entries on stderr for
.\" titles (.TH), headers (.SH), subsections (.Sh), items (.Ip), and index
.\" entries marked with X<> in POD.  Of course, you'll have to process the
.\" output yourself in some meaningful fashion.
.ie \nF \{\
.    de IX
.    tm Index:\\$1\t\\n%\t"\\$2"
..
.    nr % 0
.    rr F
.\}
.el \{\
.    de IX
..
.\}
.\"
.\" Accent mark definitions (@(#)ms.acc 1.5 88/02/08 SMI; from UCB 4.2).
.\" Fear.  Run.  Save yourself.  No user-serviceable parts.
.    \" fudge factors for nroff and troff
.if n \{\
.    ds #H 0
.    ds #V .8m
.    ds #F .3m
.    ds #[ \f1
.    ds #] \fP
.\}
.if t \{\
.    ds #H ((1u-(\\\\n(.fu%2u))*.13m)
.    ds #V .6m
.    ds #F 0
.    ds #[ \&
.    ds #] \&
.\}
.    \" simple accents for nroff and troff
.if n \{\
.    ds ' \&
.    ds ` \&
.    ds ^ \&
.    ds , \&
.    ds ~ ~
.    ds /
.\}
.if t \{\
.    ds ' \\k:\h'-(\\n(.wu*8/10-\*(#H)'\'\h"|\\n:u"
.    ds ` \\k:\h'-(\\n(.wu*8/10-\*(#H)'\`\h'|\\n:u'
.    ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'^\h'|\\n:u'
.    ds , \\k:\h'-(\\n(.wu*8/10)',\h'|\\n:u'
.    ds ~ \\k:\h'-(\\n(.wu-\*(#H-.1m)'~\h'|\\n:u'
.    ds / \\k:\h'-(\\n(.wu*8/10-\*(#H)'\z\(sl\h'|\\n:u'
.\}
.    \" troff and (daisy-wheel) nroff accents
.ds : \\k:\h'-(\\n(.wu*8/10-\*(#H+.1m+\*(#F)'\v'-\*(#V'\z.\h'.2m+\*(#F'.\h'|\\n:u'\v'\*(#V'
.ds 8 \h'\*(#H'\(*b\h'-\*(#H'
.ds o \\k:\h'-(\\n(.wu+\w'\(de'u-\*(#H)/2u'\v'-.3n'\*(#[\z\(de\v'.3n'\h'|\\n:u'\*(#]
.ds d- \h'\*(#H'\(pd\h'-\w'~'u'\v'-.25m'\f2\(hy\fP\v'.25m'\h'-\*(#H'
.ds D- D\\k:\h'-\w'D'u'\v'-.11m'\z\(hy\v'.11m'\h'|\\n:u'
.ds th \*(#[\v'.3m'\s+1I\s-1\v'-.3m'\h'-(\w'I'u*2/3)'\s-1o\s+1\*(#]
.ds Th \*(#[\s+2I\s-2\h'-\w'I'u*3/5'\v'-.3m'o\v'.3m'\*(#]
.ds ae a\h'-(\w'a'u*4/10)'e
.ds Ae A\h'-(\w'A'u*4/10)'E
.    \" corrections for vroff
.if v .ds ~ \\k:\h'-(\\n(.wu*9/10-\*(#H)'\s-2\u~\d\s+2\h'|\\n:u'
.if v .ds ^ \\k:\h'-(\\n(.wu*10/11-\*(#H)'\v'-.4m'^\v'.4m'\h'|\\n:u'
.    \" for low resolution devices (crt and lpr)
.if \n(.H>23 .if \n(.V>19 \
\{\
.    ds : e
.    ds 8 ss
.    ds o a
.    ds d- d\h'-1'\(ga
.    ds D- D\h'-1'\(hy
.    ds th \o'bp'
.    ds Th \o'LP'
.    ds ae ae
.    ds Ae AE
.\}
.rm #[ #] #H #V #F C
.\" ========================================================================
.\"
.IX Title "WWW::Spider 3"
.TH WWW::Spider 3 "2012-02-24" "perl v5.10.0" "User Contributed Perl Documentation"
.\" For nroff, turn off justification.  Always turn off hyphenation; it makes
.\" way too many mistakes in technical documents.
.if n .ad l
.nh
.SH "NAME"
WWW::Spider \- flexible Internet spider for fetching and analyzing websites
.SH "VERSION"
.IX Header "VERSION"
This document describes \f(CW\*(C`WWW::Spider\*(C'\fR version 0.01_10
.SH "SYNOPSIS"
.IX Header "SYNOPSIS"
.Vb 3
\& #configuration
\& my $spider=new WWW::Spider;
\& $spider=new WWW::Spider({UASTRING=>"mybot"});
\& 
\& print $spider\->uastring;
\& $spider\->uastring(\*(AqNew UserAgent String\*(Aq);
\& $spider\->user_agent(new LWP::UserAgent);
\& 
\& #basic stuff
\& print $spider\->get_page_response(\*(Aqhttp://search.cpan.org/\*(Aq) \-> content;
\& print $spider\->get_page_content(\*(Aqhttp://search.cpan.org/\*(Aq);
\& $spider\->get_links_from(\*(Aqhttp://google.com/\*(Aq); #get array of URLs
\& 
\& #registering hooks
\& 
\& #crawling
.Ve
.SH "DESCRIPTION"
.IX Header "DESCRIPTION"
WWW::Spider is a customizable Internet spider intended to be used for
fetching and analyzing websites.  Features include:
.IP "\(bu" 4
basic methods for high-level html handling
.IP "\(bu" 4
the manner in which pages are retrieved is customizable
.IP "\(bu" 4
callbacks for when pages are fetched, errors caused, etc...
.IP "\(bu" 4
caching
.IP "\(bu" 4
thread-safe operation, and optional multithreading operation
(faster)
.IP "\(bu" 4
a high-level implementation of a 'graph' of either pages or
sites (as defined by the callback) which can be analyzed
.SH "FUNCTIONS"
.IX Header "FUNCTIONS"
.Sh "\s-1PARAMETERS\s0"
.IX Subsection "PARAMETERS"
Parameter getting and setting functions.
.IP "new WWW::Spider([%params])" 4
.IX Item "new WWW::Spider([%params])"
Constructor for \f(CW\*(C`WWW::Spider\*(C'\fR
.Sp
Arguments include:
.RS 4
.IP "\(bu" 4
\&\s-1UASTRING\s0
.Sp
The useragent string to be used.  The default is \*(L"WWW::Spider\*(R"
.IP "\(bu" 4
\&\s-1USER_AGENT\s0
.Sp
The LWP::UserAgent to use.  If this is specified, the \s-1UASTRING\s0
argument is ignored.
.RE
.RS 4
.RE
.IP "\->user_agent [LWP::UserAgent]" 4
.IX Item "->user_agent [LWP::UserAgent]"
Returns/sets the user agent being used by this object.
.IP "\->uastring [\s-1STRING\s0]" 4
.IX Item "->uastring [STRING]"
Returns/sets the user agent string being used by this object.
.Sh "\s-1GENERAL\s0"
.IX Subsection "GENERAL"
These functions could be implemented anywhere \- nothing about what
they do is special do WWW::Spider.  Mainly, they are just conveiniance
functions for the rest of the code.
.IP "\->get_page_content \s-1URL\s0" 4
.IX Item "->get_page_content URL"
Returns the contents of the page at \s-1URL\s0.
.IP "\->get_page_response \s-1URL\s0" 4
.IX Item "->get_page_response URL"
Returns the HTTP::Response object corresponding to \s-1URL\s0
.Sh "\s-1SPIDER\s0"
.IX Subsection "SPIDER"
These functions implement the spider functionality.
.IP "\->crawl \s-1URL\s0 \s-1MAX_DEPTH\s0" 4
.IX Item "->crawl URL MAX_DEPTH"
Crawls \s-1URL\s0 to the specified maxiumum depth.  This is implemented as a
breadth-first search.
.Sp
The default value for \s-1MAX_DEPTH\s0 is 0.
.IP "\->handle_url \s-1URL\s0" 4
.IX Item "->handle_url URL"
The same as \f(CW\*(C`crawl(URL,0)\*(C'\fR.
.IP "\->crawl_content \s-1STRING\s0 [$MAX_DEPTH] [$SOURCE]" 4
.IX Item "->crawl_content STRING [$MAX_DEPTH] [$SOURCE]"
Treats \s-1STRING\s0 as if it was encountered during a crawl, with a
remaining maximum depth of \s-1MAX_DEPTH\s0.  The crawl is implemented as a
breadth-first search using \f(CW\*(C`Thread::Queue\*(C'\fR.
.Sp
The default value for \s-1MAX_DEPTH\s0 is 0.
.Sp
The assumption is made that handlers have already been called on this
page (otherwise, implementation would be impossible).
.IP "\->handle_response \s-1HTTP::RESPONSE\s0" 4
.IX Item "->handle_response HTTP::RESPONSE"
Handles the \s-1HTTP\s0 reponse, calling the appropriate hooks, without
crawling any other pages.
.IP "\->get_links_from \s-1URL\s0" 4
.IX Item "->get_links_from URL"
Returns a list of URLs linked to from \s-1URL\s0.
.ie n .IP "\->get_links_from_content $CONTENT [$SOURCE]" 4
.el .IP "\->get_links_from_content \f(CW$CONTENT\fR [$SOURCE]" 4
.IX Item "->get_links_from_content $CONTENT [$SOURCE]"
Returns a list of URLs linked to in \s-1STRING\s0.  When a \s-1URL\s0 is discovered
that is not complete, it is fixed by assuming that is was found on
\&\s-1SOURCE\s0.  If there is no source page specified, bad URLs are treated as
if they were linked to from http://localhost/.
.Sp
\&\s-1SOURCE\s0 must be a valid and complete url.
.Sh "\s-1CALLBACKS\s0 \s-1AND\s0 \s-1HOOKS\s0"
.IX Subsection "CALLBACKS AND HOOKS"
All hook registration and deletion functions are considered atomic.
If five hooks have been registered, and then all of them are deleted
in one operation, there will be no page for which fewer than five but
more than zero of those hooks are called (unless some hooks are added
afterwords).
.PP
The legal hook strings are:
.IP "\(bu" 4
handle-page
.Sp
Called whenever a crawlable page is reached.
.Sp
Arguments: \s-1CONTENT\s0, \s-1URL\s0
.Sp
Return:
.IP "\(bu" 4
handle-response
.Sp
Called on an \s-1HTTP\s0 response, successfull, crawlable, or otherwise.
.Sp
Arguments:
.Sp
Return:
.IP "\(bu" 4
handle-failure
.Sp
Called on any failed \s-1HTTP\s0 response.
.Sp
Arguments:
.Sp
Return:
.PP
Functions for handling callbacks are:
.ie n .IP "\->call_hooks HOOK-STRING, @ARGS" 4
.el .IP "\->call_hooks HOOK-STRING, \f(CW@ARGS\fR" 4
.IX Item "->call_hooks HOOK-STRING, @ARGS"
Calls all of the registered HOOK-STRING callbacks with \f(CW@ARGS\fR.  This
function returns a list of all of the return values (in some
unspecified order) which are to be handled appropriately by the
caller.
.IP "\->register_hook HOOK-STRING, \s-1SUB\s0, [{\s-1OPTIONS\s0}]" 4
.IX Item "->register_hook HOOK-STRING, SUB, [{OPTIONS}]"
Registers a subroutine to be run on HOOK-STRING.  Has no return value.
Valid options are:
.RS 4
.IP "\(bu" 4
\&\s-1FORK\s0
.Sp
Set to a non-zero value if you want this hook to be run in a separate
thread.  This means that, among other things, the return value will
not have the same affect (or even a well defined affect).
.RE
.RS 4
.RE
.IP "\->get_hooks [\s-1HOOK\-STRING\s0]" 4
.IX Item "->get_hooks [HOOK-STRING]"
Returns all hooks corresponding to HOOK-STRING.  If HOOK-STRING is not
given, returns all hooks.
.IP "\->clear_hooks [\s-1HOOK\-STRING\s0]" 4
.IX Item "->clear_hooks [HOOK-STRING]"
Removes all hooks corresponding to HOOK-STRING.  If HOOK-STRING is not
given, it deletes all hooks.
.SH "BUGS AND LIMITATIONS"
.IX Header "BUGS AND LIMITATIONS"
.IP "\(bu" 4
Hooks are not yet fully implemented.
.IP "\(bu" 4
Hook list modifications are not atomic
.SH "MODULE DEPENDENCIES"
.IX Header "MODULE DEPENDENCIES"
WWW::Spider depends on several other modules that allow it to get and
parse \s-1HTML\s0 code.  Currently used are:
.IP "\(bu" 4
\&\f(CW\*(C`Carp\*(C'\fR
.IP "\(bu" 4
\&\f(CW\*(C`LWP::UserAgent\*(C'\fR
.IP "\(bu" 4
\&\f(CW\*(C`HTTP::Request\*(C'\fR
.IP "\(bu" 4
\&\f(CW\*(C`Thread::Queue\*(C'\fR
.IP "\(bu" 4
\&\f(CW\*(C`Thread::Resource::RWLock\*(C'\fR
.PP
Other modules will likely be added to this list in the future.  Candidates are:
.IP "\(bu" 4
HTML::*
.SH "SEE ALSO"
.IX Header "SEE ALSO"
.IP "\(bu" 4
\&\f(CW\*(C`WWW::Robot\*(C'\fR
.Sp
Another web crawler, with rather different capabilities.
.IP "\(bu" 4
\&\f(CW\*(C`WWW::Spider::Graph\*(C'\fR
.Sp
Implementation of a graph based on WWW::Spider.
.IP "\(bu" 4
\&\f(CW\*(C`WWW::Spider::Hooklist\*(C'\fR
.Sp
A thread-safe list of hooks.
.SH "AUTHOR"
.IX Header "AUTHOR"
\&\f(CW\*(C`WWW::Spider\*(C'\fR is written and maintained by Scott Lawrence (bytbox@gmail.com)
.SH "COPYRIGHT AND LICENSE"
.IX Header "COPYRIGHT AND LICENSE"
Copyright 2009 Scott Lawrence, all rights reserved.
.PP
This program is free software; you can redistribute it and/or modify it
under the same terms as Perl itself.
